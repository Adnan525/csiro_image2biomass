{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":112509,"databundleVersionId":14254895,"sourceType":"competition"}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nimport torchvision.transforms as transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:03:57.949482Z","iopub.execute_input":"2026-01-06T13:03:57.949953Z","iopub.status.idle":"2026-01-06T13:04:09.391077Z","shell.execute_reply.started":"2026-01-06T13:03:57.949921Z","shell.execute_reply":"2026-01-06T13:04:09.389829Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from PIL import Image\nfrom collections import defaultdict\nfrom torchvision.models import resnet34\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:04:18.397271Z","iopub.execute_input":"2026-01-06T13:04:18.398245Z","iopub.status.idle":"2026-01-06T13:04:18.590295Z","shell.execute_reply.started":"2026-01-06T13:04:18.398212Z","shell.execute_reply":"2026-01-06T13:04:18.589162Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"folders = [\n    \"/kaggle/input/csiro-biomass/train\",\n    \"/kaggle/input/csiro-biomass/test\",\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:04:18.749082Z","iopub.execute_input":"2026-01-06T13:04:18.749887Z","iopub.status.idle":"2026-01-06T13:04:18.754219Z","shell.execute_reply.started":"2026-01-06T13:04:18.749846Z","shell.execute_reply":"2026-01-06T13:04:18.753070Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def get_unique_sizes(directory):\n    size_counts = defaultdict(int)\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.lower().endswith(('.png', '.jpg', '.jpeg', 'JPG')):\n                try:\n                    with Image.open(os.path.join(root, file)) as img:\n                        size = img.size\n                        size_counts[size] += 1\n                except Exception as e:\n                    print(f\"Error {file}: {e}\")\n\n    return size_counts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:05:30.326073Z","iopub.execute_input":"2026-01-06T13:05:30.326391Z","iopub.status.idle":"2026-01-06T13:05:30.333487Z","shell.execute_reply.started":"2026-01-06T13:05:30.326368Z","shell.execute_reply":"2026-01-06T13:05:30.332491Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"for folder in folders:\n    print(get_unique_sizes(folder))\n    print()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:09:19.568439Z","iopub.execute_input":"2026-01-06T13:09:19.569361Z","iopub.status.idle":"2026-01-06T13:09:19.967747Z","shell.execute_reply.started":"2026-01-06T13:09:19.569331Z","shell.execute_reply":"2026-01-06T13:09:19.966827Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/csiro-biomass/train\n[]\ndefaultdict(<class 'int'>, {(2000, 1000): 357})\n\n/kaggle/input/csiro-biomass/test\n[]\ndefaultdict(<class 'int'>, {(2000, 1000): 1})\n\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/csiro-biomass/train.csv')\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:10:18.657171Z","iopub.execute_input":"2026-01-06T13:10:18.657635Z","iopub.status.idle":"2026-01-06T13:10:18.713065Z","shell.execute_reply.started":"2026-01-06T13:10:18.657581Z","shell.execute_reply":"2026-01-06T13:10:18.711978Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                    sample_id              image_path Sampling_Date State  \\\n0  ID1011485656__Dry_Clover_g  train/ID1011485656.jpg      2015/9/4   Tas   \n1    ID1011485656__Dry_Dead_g  train/ID1011485656.jpg      2015/9/4   Tas   \n2   ID1011485656__Dry_Green_g  train/ID1011485656.jpg      2015/9/4   Tas   \n3   ID1011485656__Dry_Total_g  train/ID1011485656.jpg      2015/9/4   Tas   \n4         ID1011485656__GDM_g  train/ID1011485656.jpg      2015/9/4   Tas   \n\n           Species  Pre_GSHH_NDVI  Height_Ave_cm   target_name   target  \n0  Ryegrass_Clover           0.62         4.6667  Dry_Clover_g   0.0000  \n1  Ryegrass_Clover           0.62         4.6667    Dry_Dead_g  31.9984  \n2  Ryegrass_Clover           0.62         4.6667   Dry_Green_g  16.2751  \n3  Ryegrass_Clover           0.62         4.6667   Dry_Total_g  48.2735  \n4  Ryegrass_Clover           0.62         4.6667         GDM_g  16.2750  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>image_path</th>\n      <th>Sampling_Date</th>\n      <th>State</th>\n      <th>Species</th>\n      <th>Pre_GSHH_NDVI</th>\n      <th>Height_Ave_cm</th>\n      <th>target_name</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID1011485656__Dry_Clover_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Clover_g</td>\n      <td>0.0000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID1011485656__Dry_Dead_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Dead_g</td>\n      <td>31.9984</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID1011485656__Dry_Green_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Green_g</td>\n      <td>16.2751</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID1011485656__Dry_Total_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>Dry_Total_g</td>\n      <td>48.2735</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID1011485656__GDM_g</td>\n      <td>train/ID1011485656.jpg</td>\n      <td>2015/9/4</td>\n      <td>Tas</td>\n      <td>Ryegrass_Clover</td>\n      <td>0.62</td>\n      <td>4.6667</td>\n      <td>GDM_g</td>\n      <td>16.2750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"train[\"target_name\"].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:22:25.498483Z","iopub.execute_input":"2026-01-06T13:22:25.499485Z","iopub.status.idle":"2026-01-06T13:22:25.510967Z","shell.execute_reply.started":"2026-01-06T13:22:25.499450Z","shell.execute_reply":"2026-01-06T13:22:25.509592Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array(['Dry_Clover_g', 'Dry_Dead_g', 'Dry_Green_g', 'Dry_Total_g',\n       'GDM_g'], dtype=object)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class DatasetCS(Dataset):\n    def __init__(self, \n                 df: pd.DataFrame, \n                 images_dir: str, \n                 transform: callable = None, \n                 is_test: bool = False):\n        self.df = df\n        self.images_dir = images_dir\n        self.transform = transform\n        self.is_test = is_test\n        \n        if not is_test:\n            self.target_mapping = {\n                'Dry_Green_g': 0, \n                'Dry_Dead_g': 1, \n                'Dry_Clover_g': 2,\n                'GDM_g': 3, \n                'Dry_Total_g': 4\n            }\n\n    \n    def __len__(self):\n        return len(self.df)\n\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = os.path.join(self.images_dir, row['image_path'])\n        \n        image = Image.open(image_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, row['sample_id']\n        else:\n            target_value = row['target']\n            target_type = self.target_mapping[row['target_name']]\n            return image, torch.tensor(target_value, dtype=torch.float32), target_type","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-06T13:27:15.398195Z","iopub.execute_input":"2026-01-06T13:27:15.398557Z","iopub.status.idle":"2026-01-06T13:27:15.407291Z","shell.execute_reply.started":"2026-01-06T13:27:15.398532Z","shell.execute_reply":"2026-01-06T13:27:15.406336Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((500, 250)),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # zscore norm, image net values\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((500, 250)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet34(nn.Module):\n    def __init__(self, num_targets=5):\n        super(ResNet34, self).__init__()\n        self.backbone = resnet34(weights=None)\n        self.backbone.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        \n        in_features = self.backbone.fc.in_features\n        self.backbone.fc = nn.Identity()\n        \n        self.shared_features = nn.Sequential(\n            nn.Linear(in_features, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(inplace=True),\n        )\n        \n        self.heads = nn.ModuleList([\n            nn.Sequential(\n                nn.Dropout(0.2),\n                nn.Linear(256, 128),\n                nn.ReLU(inplace=True),\n                nn.Linear(128, 1)\n            ) for _ in range(num_targets)\n        ])\n        \n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n    \n    def forward(self, x, target_type=None):\n        features = self.backbone(x)\n        shared_out = self.shared_features(features)\n        \n        if target_type is not None:\n            outputs = []\n            for i, t_type in enumerate(target_type):\n                outputs.append(self.heads[t_type](shared_out[i].unsqueeze(0)))\n            return torch.cat(outputs, dim=0)\n        else:\n            all_outputs = [head(shared_out) for head in self.heads]\n            return torch.cat(all_outputs, dim=1)\ntraining ->\n\ndef train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=15):\n    train_losses = []\n    val_losses = []\n    \n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        \n        for images, targets, target_types in train_loader:\n            images = images.to(device)\n            targets = targets.to(device)\n            target_types = target_types.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(images, target_types).squeeze()\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n        \n        model.eval()\n        val_loss = 0.0\n        \n        with torch.no_grad():\n            for images, targets, target_types in val_loader:\n                images = images.to(device)\n                targets = targets.to(device)\n                target_types = target_types.to(device)\n                \n                outputs = model(images, target_types).squeeze()\n                loss = criterion(outputs, targets)\n                val_loss += loss.item()\n        \n        train_loss /= len(train_loader)\n        val_loss /= len(val_loader)\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        \n        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    \n    return train_losses, val_losses\nnot sure ->\n\ntrain_indices, val_indices = train_test_split(\n    range(len(train)), \n    test_size=0.2, \n    random_state=42, \n    stratify=train['target_name']\n)\n\ntrain_subset = train.iloc[train_indices].reset_index(drop=True)\nval_subset = train.iloc[val_indices].reset_index(drop=True)\n\nprint(f\"train length: {len(train_subset)}\")\nprint(f\"val length: {len(val_subset)}\")\nnot sure ->\n\ntrain_dataset = DatasetCS(train_subset, '/kaggle/input/csiro-biomass', transform=train_transform)\nval_dataset = DatasetCS(val_subset, '/kaggle/input/csiro-biomass', transform=val_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice\nactual training ->\n\nmodel = ResNet34(num_targets=5).to(device)\n\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, factor=0.5)\n\ntrain_losses, val_losses = train_model(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    num_epochs=3\n)\ntest->\n\ntest = pd.read_csv('/kaggle/input/csiro-biomass/test.csv')\ntest_dataset = DatasetCS(test, '/kaggle/input/csiro-biomass', transform=val_transform, is_test=True)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=2)\n\nmodel.eval()\npredictions = []\nsample_ids = []\n\ntarget_mapping = {\n    'Dry_Green_g': 0, 'Dry_Dead_g': 1, 'Dry_Clover_g': 2,\n    'GDM_g': 3, 'Dry_Total_g': 4\n}\n\nwith torch.no_grad():\n    for images, batch_sample_ids in test_loader:\n        images = images.to(device)\n        batch_outputs = model(images)\n        \n        for i, sample_id in enumerate(batch_sample_ids):\n            row = test[test['sample_id'] == sample_id].iloc[0]\n            target_idx = target_mapping[row['target_name']]\n            prediction = batch_outputs[i, target_idx].item()\n            predictions.append(prediction)\n            sample_ids.append(sample_id)\n\nsubmission = pd.DataFrame({\n    'sample_id': sample_ids,\n    'target': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\nsubmission","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}